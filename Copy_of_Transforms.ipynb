{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Transforms.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aryama-ray/pgdds/blob/arymain/Copy_of_Transforms.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvA5iwv_6yyV"
      },
      "source": [
        "\r\n",
        "\r\n",
        "'''\r\n",
        "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\r\n",
        "during creation of the DataSet\r\n",
        "complete list of built-in transforms: \r\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html\r\n",
        "On Images\r\n",
        "---------\r\n",
        "CenterCrop, Grayscale, Pad, RandomAffine\r\n",
        "RandomCrop, RandomHorizontalFlip, RandomRotation\r\n",
        "Resize, Scale\r\n",
        "On Tensors\r\n",
        "----------\r\n",
        "LinearTransformation, Normalize, RandomErasing\r\n",
        "Conversion\r\n",
        "----------\r\n",
        "ToPILImage: from tensor or ndrarray\r\n",
        "ToTensor : from numpy.ndarray or PILImage\r\n",
        "Generic\r\n",
        "-------\r\n",
        "Use Lambda \r\n",
        "Custom\r\n",
        "------\r\n",
        "Write own class\r\n",
        "Compose multiple Transforms\r\n",
        "---------------------------\r\n",
        "composed = transforms.Compose([Rescale(256),\r\n",
        "                               RandomCrop(224)])\r\n",
        "'''\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GWyAXDd6qvG"
      },
      "source": [
        "import torch\r\n",
        "import torchvision\r\n",
        "from torch.utils.data import Dataset\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkLleZqS63hz"
      },
      "source": [
        "class WineDataset(Dataset):\r\n",
        "\r\n",
        "    def __init__(self, transform=None):\r\n",
        "        xy = np.loadtxt('./data/wine/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\r\n",
        "        self.n_samples = xy.shape[0]\r\n",
        "\r\n",
        "        # note that we do not convert to tensor here\r\n",
        "        self.x_data = xy[:, 1:]\r\n",
        "        self.y_data = xy[:, [0]]\r\n",
        "\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        sample = self.x_data[index], self.y_data[index]\r\n",
        "\r\n",
        "        if self.transform:\r\n",
        "            sample = self.transform(sample)\r\n",
        "\r\n",
        "        return sample\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return self.n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU2EazO766bB"
      },
      "source": [
        "# Custom Transforms\r\n",
        "# implement __call__(self, sample)\r\n",
        "class ToTensor:\r\n",
        "    # Convert ndarrays to Tensors\r\n",
        "    def __call__(self, sample):\r\n",
        "        inputs, targets = sample\r\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\r\n",
        "\r\n",
        "class MulTransform:\r\n",
        "    # multiply inputs with a given factor\r\n",
        "    def __init__(self, factor):\r\n",
        "        self.factor = factor\r\n",
        "\r\n",
        "    def __call__(self, sample):\r\n",
        "        inputs, targets = sample\r\n",
        "        inputs *= self.factor\r\n",
        "        return inputs, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9f64pXq694R"
      },
      "source": [
        "print('Without Transform')\r\n",
        "dataset = WineDataset()\r\n",
        "first_data = dataset[0]\r\n",
        "features, labels = first_data\r\n",
        "print(type(features), type(labels))\r\n",
        "print(features, labels)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3jfARQc7CJq"
      },
      "source": [
        "print('\\nWith Tensor Transform')\r\n",
        "dataset = WineDataset(transform=ToTensor())\r\n",
        "first_data = dataset[0]\r\n",
        "features, labels = first_data\r\n",
        "print(type(features), type(labels))\r\n",
        "print(features, labels)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZAe5tVs7Dya"
      },
      "source": [
        "print('\\nWith Tensor and Multiplication Transform')\r\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\r\n",
        "dataset = WineDataset(transform=composed)\r\n",
        "first_data = dataset[0]\r\n",
        "features, labels = first_data\r\n",
        "print(type(features), type(labels))\r\n",
        "print(features, labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}